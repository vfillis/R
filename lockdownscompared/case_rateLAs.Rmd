---
title: "Case rate in Englands' local authorities"
author: "Vanessa Fillis"
date: "23/11/2020"
output: html_document
---

# Looking at daily cases since the beginning of the second lockdown / shortly before the second lockdown in England's regions

We cannot look at daily covid cases to the lockdowns to each other since the testing capacity has increased since March. 

Instead we will look at new cases in Enland's regions to see how they have developed since before the second lockdown. 

Daily cases by date reported and by nation can be found on the [website of the UK government]("https://coronavirus.data.gov.uk/details/deaths"). 

Since the second lockdown isn't imposed UK-wide, but England, Scotland, Wales and Northern Ireland each have different restrictions, it is important to import data that offers the deaths for each nation. We will only compare the deaths in England during the first and the second lockdown to each other. 

## Activating packages

At first, we will activate necessary packages. 

```{r}
library(jsonlite)
library(httr)
library(dplyr)
```

## Importing the data

We will import the data of all daily cases in England's regions since the beginning. 

### Cases Upper-tier local authorities

Cases by specimen date (regional breakdown of cases is only available by specimen date)

```{r}
#' Extracts paginated data by requesting all of the pages
#' and combining the results.
#'
#' @param filters    API filters. See the API documentations for 
#'                   additional information.
#'                   
#' @param structure  Structure parameter. See the API documentations 
#'                   for additional information.
#'                   
#' @return list      Comprehensive list of dictionaries containing all 
#'                   the data for the given ``filter`` and ``structure`.`
get_paginated_data <- function (filters, structure) {
  
    endpoint     <- "https://api.coronavirus.data.gov.uk/v1/data"
    results      <- list()
    current_page <- 1
    
    repeat {

        httr::GET(
            url   = endpoint,
            query = list(
                filters   = paste(filters, collapse = ";"),
                structure = jsonlite::toJSON(structure, auto_unbox = TRUE),
                page      = current_page
            ),
            timeout(10)
        ) -> response
        
        # Handle errors:
        if ( response$status_code >= 400 ) {
            err_msg = httr::http_status(response)
            stop(err_msg)
        } else if ( response$status_code == 204 ) {
            break
        }
        
        # Convert response from binary to JSON:
        json_text <- content(response, "text")
        dt        <- jsonlite::fromJSON(json_text)
        results   <- rbind(results, dt$data)
        
        if ( is.null( dt$pagination$`next` ) ){
            break
        }
        
        current_page <- current_page + 1;

    }
    
    return(results)
    
}

# Create filters:
query_filters <- c(
    "areaType=utla"
)

# Create the structure as a list or a list of lists:
query_structure <- list(
    date       = "date", 
    name       = "areaName", 
    code       = "areaCode", 
    daily      = "newCasesBySpecimenDate",
    cumulative = "cumCasesBySpecimenDate"
)

cases.upperLA <- get_paginated_data(query_filters, query_structure)

list(
  "Shape"                = dim(cases.upperLA),
  "Data (first 3 items)" = cases.upperLA[0:3, 0:-1]
) -> report

print(report)

# Rename columns for better distinction
cases.upperLA <- cases.upperLA %>%
  rename(
    daily.cases = daily,
    cumulative.cases = cumulative
  )
```

## Cases Lower-tier local authorities

Cases by specimen date (regional breakdown of cases is only available by specimen date)

```{r}
#' Extracts paginated data by requesting all of the pages
#' and combining the results.
#'
#' @param filters    API filters. See the API documentations for 
#'                   additional information.
#'                   
#' @param structure  Structure parameter. See the API documentations 
#'                   for additional information.
#'                   
#' @return list      Comprehensive list of dictionaries containing all 
#'                   the data for the given ``filter`` and ``structure`.`
get_paginated_data <- function (filters, structure) {
  
    endpoint     <- "https://api.coronavirus.data.gov.uk/v1/data"
    results      <- list()
    current_page <- 1
    
    repeat {

        httr::GET(
            url   = endpoint,
            query = list(
                filters   = paste(filters, collapse = ";"),
                structure = jsonlite::toJSON(structure, auto_unbox = TRUE),
                page      = current_page
            ),
            timeout(10)
        ) -> response
        
        # Handle errors:
        if ( response$status_code >= 400 ) {
            err_msg = httr::http_status(response)
            stop(err_msg)
        } else if ( response$status_code == 204 ) {
            break
        }
        
        # Convert response from binary to JSON:
        json_text <- content(response, "text")
        dt        <- jsonlite::fromJSON(json_text)
        results   <- rbind(results, dt$data)
        
        if ( is.null( dt$pagination$`next` ) ){
            break
        }
        
        current_page <- current_page + 1;

    }
    
    return(results)
    
}


# Create filters:
query_filters <- c(
    "areaType=ltla"
)

# Create the structure as a list or a list of lists:
query_structure <- list(
    date       = "date", 
    name       = "areaName", 
    code       = "areaCode", 
    daily      = "newCasesBySpecimenDate",
    cumulative = "cumCasesBySpecimenDate"
)

cases.lowerLA <- get_paginated_data(query_filters, query_structure)

list(
  "Shape"                = dim(cases.lowerLA),
  "Data (first 3 items)" = cases.lowerLA[0:3, 0:-1]
) -> report

print(report)

# Rename columns for better distinction
cases.lowerLA <- cases.lowerLA %>%
  rename(
    daily.cases = daily,
    cumulative.cases = cumulative
  )
```

## Remove local authorities from Scotland and Wales

We will only look at local authorities in England. Their code starts with an "E". 

```{r}
cases.lowerLA$England <- grepl("[E]+", cases.lowerLA$code)

#Remove rows for LAs in Scotland and Wales
cases.lowerLA <- subset(cases.lowerLA, cases.lowerLA$England == TRUE)
```

## Rate of positive cases per 100,000 population  

### Import population estimates from mid 2019

Populations used are [Office for National Statistics 2019 mid-year estimates](https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/populationestimatesforukenglandandwalesscotlandandnorthernireland). 

```{r}
population.estimates <- read.csv("population estimates_mid2019.csv", stringsAsFactors = FALSE)

#Rename column "code" for merging
population.estimates <- population.estimates %>%
  rename(code = Code)
```

## Lookup the population for the regions

Continue working with data for lower local authorities (what's the difference between lower and upper?)

```{r}
cases.lowerLA <- merge(cases.lowerLA, population.estimates, by = "code")

#Dropping duplicate columns
cases.lowerLA <- cases.lowerLA[-c(6,7)]

#Rename column with populations estimates
cases.lowerLA <- cases.lowerLA %>%
  rename(
    population = All.ages
  )
```

## Calculate cases per 100,000

Divide daily cases by population and then multiply with 100,000

```{r}
cases.lowerLA$case.rate <- (cases.lowerLA$daily.cases/cases.lowerLA$population)*100000
```

## Export 

```{r}
write.csv(cases.lowerLA, file = "cases_England_lowerLAs.csv")
```

## Further analysis

## Looking at cases in last seven days 

```{r}
cases.lowerLA.lastweek <- subset(cases.lowerLA, cases.lowerLA$date >= "2020-11-15" & cases.lowerLA$date <= "2020-11-21")

cases.lowerLA.penultimateweek <- subset(cases.lowerLA, cases.lowerLA$date >= "2020-11-07" & cases.lowerLA$date <= "2020-11-13")
```

## Sum of case rate in the last 7 days for each LA

```{r}
sum.cases.lowerLA.lastweek <- cases.lowerLA.lastweek %>%
  group_by(name) %>%
  summarise(sum.caserate = sum(case.rate))

sum.cases.lowerLA.penultimateweek <- cases.lowerLA.penultimateweek %>%
  group_by(name) %>%
  summarise(sum.caserate = sum(case.rate))

#Join both data frames
sum.cases.lowerLA <- left_join(sum.cases.lowerLA.lastweek, sum.cases.lowerLA.penultimateweek, by = "name", suffix = c(".lastweek", ".penultimateweek"))

#Change last and penultimate week 
sum.cases.lowerLA$change <- sum.cases.lowerLA$sum.caserate.lastweek - sum.cases.lowerLA$sum.caserate.penultimateweek
```

##Export 

```{r}
write.csv(sum.cases.lowerLA, file = "case_rate_LAs_last14.csv")
```

